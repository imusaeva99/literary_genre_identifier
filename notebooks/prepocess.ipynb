{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"ru_core_news_lg\")\n",
    "nlp.max_length = 4000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(filename, genre):\n",
    "\n",
    "    with open('../datasets/' + genre + '/' + filename, 'r', encoding='utf-8') as f:\n",
    "        lines = f.read()\n",
    "\n",
    "    lemmas = []\n",
    "    doc = nlp(lines, disable = ['ner', 'parser'])\n",
    "    for token in doc:\n",
    "        if token.lemma_.isalpha():\n",
    "            lemmas.append(token.lemma_)\n",
    "\n",
    "    path = '../datasets/lemmatized/' + genre\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    with open(path + '/' + filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(' '.join(lemmas))\n",
    "\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = ['ballads', 'elegies', 'songs', 'novels']\n",
    "\n",
    "for genre in genres:\n",
    "\n",
    "    filenames = os.listdir('../datasets/' + genre)\n",
    "\n",
    "    for file in filenames:\n",
    "        if file != '.DS_Store':\n",
    "            spacy_doc = lemmatize(file, genre)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
